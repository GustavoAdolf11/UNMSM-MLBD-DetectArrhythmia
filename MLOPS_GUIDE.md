# ğŸš€ GuÃ­a MLOps - DetecciÃ³n de Arritmias ECG

Esta guÃ­a te ayudarÃ¡ a utilizar las herramientas MLOps implementadas en el proyecto para automatizar el ciclo de vida del modelo de Machine Learning.

## ğŸ“‹ Tabla de Contenidos

- [Â¿QuÃ© es MLOps?](#quÃ©-es-mlops)
- [Arquitectura MLOps del Proyecto](#arquitectura-mlops-del-proyecto)
- [Inicio RÃ¡pido](#inicio-rÃ¡pido)
- [Uso de MLflow](#uso-de-mlflow)
- [Pipelines CI/CD](#pipelines-cicd)
- [Monitoreo y Drift Detection](#monitoreo-y-drift-detection)
- [ComparaciÃ³n de Experimentos](#comparaciÃ³n-de-experimentos)
- [Despliegue de Modelos](#despliegue-de-modelos)

---

## ğŸ¯ Â¿QuÃ© es MLOps?

MLOps (Machine Learning Operations) automatiza el ciclo completo de vida de los modelos:

1. **Versionado**: CÃ³digo, datos y modelos
2. **ExperimentaciÃ³n**: Tracking de hiperparÃ¡metros y mÃ©tricas
3. **CI/CD**: Entrenamiento y validaciÃ³n automÃ¡tica
4. **Monitoreo**: Detectar degradaciÃ³n del modelo
5. **Reentrenamiento**: Actualizar modelos automÃ¡ticamente

---

## ğŸ—ï¸ Arquitectura MLOps del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CÃ³digo Fuente  â”‚
â”‚ (deteccionarr..â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLflow Track   â”‚â—„â”€â”€â”€â”€ Registra experimentos
â”‚  â€¢ ParÃ¡metros   â”‚
â”‚  â€¢ MÃ©tricas     â”‚
â”‚  â€¢ Artefactos   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Registry  â”‚â—„â”€â”€â”€â”€ Versiona modelos
â”‚ ECG_Arritmias_  â”‚
â”‚     NvsV        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub        â”‚â—„â”€â”€â”€â”€ CI/CD automÃ¡tico
â”‚   Actions       â”‚
â”‚ â€¢ Train         â”‚
â”‚ â€¢ Test          â”‚
â”‚ â€¢ Deploy        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚â—„â”€â”€â”€â”€ Detecta drift
â”‚ â€¢ Data Drift    â”‚
â”‚ â€¢ Performance   â”‚
â”‚ â€¢ Alerts        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Inicio RÃ¡pido

### 1. Instalar Dependencias

```powershell
pip install -r requirements-api.txt
```

Esto instalarÃ¡:
- `mlflow` - Tracking y registro de modelos
- `evidently` - Monitoreo de drift
- `optuna` - OptimizaciÃ³n de hiperparÃ¡metros (futuro)

### 2. Entrenar con MLflow

```powershell
python deteccionarritmias.py
```

El script ahora automÃ¡ticamente:
- âœ… Registra todos los hiperparÃ¡metros
- âœ… Trackea mÃ©tricas de entrenamiento
- âœ… Guarda el modelo en MLflow
- âœ… Genera visualizaciones

### 3. Ver Experimentos en MLflow UI

```powershell
# OpciÃ³n 1: Script automÃ¡tico
.\start_mlflow.ps1

# OpciÃ³n 2: Comando directo
mlflow ui
```

Luego abre: **http://127.0.0.1:5000**

---

## ğŸ“Š Uso de MLflow

### Ver Todos tus Experimentos

En la interfaz de MLflow verÃ¡s:

```
Experimento: deteccion_arritmias_ecg
â”œâ”€â”€ Run: CNN_v7_20251218_143022
â”‚   â”œâ”€â”€ Parameters (15)
â”‚   â”‚   â”œâ”€â”€ deriv_idx: 0
â”‚   â”‚   â”œâ”€â”€ fs: 360
â”‚   â”‚   â”œâ”€â”€ use_augment: True
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Metrics (25)
â”‚   â”‚   â”œâ”€â”€ test_accuracy: 0.9234
â”‚   â”‚   â”œâ”€â”€ test_precision_V: 0.8567
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Artifacts
â”‚       â”œâ”€â”€ model/ (modelo completo)
â”‚       â”œâ”€â”€ training_curves.png
â”‚       â””â”€â”€ ...
â””â”€â”€ Run: CNN_v7_20251218_150133
    â””â”€â”€ ...
```

### Comparar Experimentos

1. Selecciona mÃºltiples runs (checkbox)
2. Click en "Compare"
3. Visualiza diferencias en:
   - ParÃ¡metros
   - MÃ©tricas
   - GrÃ¡ficos lado a lado

### Cargar un Modelo Guardado

```python
import mlflow

# Cargar modelo por Run ID
model = mlflow.keras.load_model("runs:/<RUN_ID>/model")

# O por nombre y versiÃ³n
model = mlflow.pyfunc.load_model("models:/ECG_Arritmias_NvsV/1")
```

### Buscar el Mejor Modelo

```python
import mlflow

mlflow.set_tracking_uri("file:./mlruns")
experiment = mlflow.get_experiment_by_name("deteccion_arritmias_ecg")

# Buscar runs ordenados por F1 score
runs = mlflow.search_runs(
    experiment_ids=[experiment.experiment_id],
    order_by=["metrics.test_f1_V DESC"],
    max_results=5
)

print("Top 5 modelos:")
print(runs[['run_id', 'metrics.test_f1_V', 'metrics.test_accuracy']])
```

---

## ğŸ¤– Pipelines CI/CD

### Pipeline de Entrenamiento (`.github/workflows/mlops-train.yml`)

**Se ejecuta cuando:**
- Push a `main` o `develop`
- Pull Request
- Manualmente desde GitHub
- Cada domingo a las 2 AM (reentrenamiento semanal)

**Pasos:**
1. âœ… Instala dependencias
2. âœ… Verifica datos MIT-BIH
3. âœ… Ejecuta tests
4. âœ… Entrena modelo
5. âœ… Valida mÃ©tricas mÃ­nimas
6. âœ… Archiva artefactos

**Umbrales de validaciÃ³n:**
```yaml
accuracy >= 0.80
precision_V >= 0.75
recall_V >= 0.75
```

### Pipeline de Monitoreo (`.github/workflows/monitoring.yml`)

**Se ejecuta:**
- Cada lunes a las 3 AM
- Manualmente desde GitHub

**Detecta:**
- Data drift en features
- Cambios en distribuciones
- DegradaciÃ³n del modelo

### Ejecutar Manualmente

1. Ve a tu repositorio en GitHub
2. Click en "Actions"
3. Selecciona el workflow
4. Click en "Run workflow"

---

## ğŸ” Monitoreo y Drift Detection

### Â¿QuÃ© es Data Drift?

Cuando la distribuciÃ³n de datos de producciÃ³n cambia respecto al entrenamiento, el modelo puede degradarse.

### Usar el Detector de Drift

```python
from monitoring.drift_detector import ECGDriftDetector
import pandas as pd

# Cargar datos de referencia (baseline)
reference_data = pd.read_csv('reference_features.csv')

# Datos actuales de producciÃ³n
current_data = pd.read_csv('production_features.csv')

# Detectar drift
detector = ECGDriftDetector()
detector.load_reference_data(reference_data)
results = detector.detect_drift(current_data)

if results['drift_detected']:
    print(f"âš ï¸  Drift detectado en: {results['drifted_features']}")
    # Trigger reentrenamiento
```

### Monitoreo Continuo

El workflow `monitoring.yml` ejecuta automÃ¡ticamente:

```bash
python monitoring/drift_detector.py
```

Genera:
- `drift_report_<timestamp>.html` - VisualizaciÃ³n completa
- `drift_summary_<timestamp>.json` - Resumen ejecutable
- `drift_alerts.log` - Log de alertas

---

## ğŸ”¬ ComparaciÃ³n de Experimentos

### Ejemplo: Probar diferentes configuraciones

**Experimento 1: Sin augmentation**
```python
# En deteccionarritmias.py
USE_AUGMENT = False
```

**Experimento 2: Con augmentation**
```python
USE_AUGMENT = True
```

**Experimento 3: Sin RuleGuard**
```python
USE_RULEGUARD = False
```

DespuÃ©s de entrenar los 3, en MLflow UI:
1. Selecciona los 3 runs
2. Click "Compare"
3. Observa:
   - `test_f1_V`: Â¿CuÃ¡l tiene mejor F1?
   - `test_FP`: Â¿CuÃ¡l reduce falsos positivos?
   - Training time

### Tags Personalizados

Agrega tags para organizar experimentos:

```python
mlflow.set_tags({
    "developer": "tu_nombre",
    "experiment_type": "hyperparameter_tuning",
    "notes": "Probando focal loss con alpha=0.4"
})
```

---

## ğŸš€ Despliegue de Modelos

### Promover Modelo a ProducciÃ³n

```python
import mlflow

client = mlflow.tracking.MlflowClient()

# Obtener Ãºltima versiÃ³n del modelo
model_name = "ECG_Arritmias_NvsV"
latest_version = client.get_latest_versions(model_name)[0]

# Promover a producciÃ³n
client.transition_model_version_stage(
    name=model_name,
    version=latest_version.version,
    stage="Production"
)
```

### Servir Modelo con MLflow

```powershell
# Servir el modelo en producciÃ³n
mlflow models serve -m "models:/ECG_Arritmias_NvsV/Production" -p 5001
```

Luego hacer predicciones:

```python
import requests
import json

data = {
    "instances": [{
        "sig": [...],  # 360 valores
        "rr": [0.8, 0.82, 1.025]
    }]
}

response = requests.post(
    "http://127.0.0.1:5001/invocations",
    json=data,
    headers={"Content-Type": "application/json"}
)

print(response.json())
```

---

## ğŸ“ˆ MÃ©tricas Registradas

### HiperparÃ¡metros
- `deriv_idx`, `fs`, `win`
- `use_augment`, `use_ruleguard`
- `focal_gamma`, `focal_alpha`
- `batch_size`, `epochs_max`
- `target_prec`, `target_rec`

### MÃ©tricas de Datos
- `train_samples_total`, `test_samples_total`
- `train_V_balanced`, `train_N_balanced`
- `balance_ratio`

### MÃ©tricas de Entrenamiento (por Ã©poca)
- `train_loss`, `train_accuracy`, `train_pr_auc`
- `val_loss`, `val_accuracy`, `val_pr_auc`

### MÃ©tricas de Test
- `test_accuracy`
- `test_precision_V`, `test_recall_V`, `test_f1_V`
- `test_precision_N`, `test_recall_N`, `test_f1_N`
- `test_TN`, `test_FP`, `test_FN`, `test_TP`

### Artefactos
- `model/` - Modelo completo (Keras)
- `training_curves.png` - GrÃ¡ficas de entrenamiento
- `models/model_v7.keras` - Archivo .keras
- `metadata/meta_v7.json` - Metadatos
- `metrics/history_v7.csv` - Historial completo

---

## ğŸ› ï¸ Comandos Ãštiles

### MLflow CLI

```powershell
# Ver experimentos
mlflow experiments list

# Ver runs de un experimento
mlflow runs list --experiment-id 0

# Eliminar un run
mlflow runs delete --run-id <RUN_ID>

# Buscar runs
mlflow runs search --experiment-id 0 --filter "metrics.test_f1_V > 0.85"
```

### Python API

```python
import mlflow

# Configurar tracking
mlflow.set_tracking_uri("file:./mlruns")

# Listar experimentos
experiments = mlflow.search_experiments()

# Buscar runs
runs = mlflow.search_runs(
    filter_string="metrics.test_accuracy > 0.90"
)

# Obtener mÃ©trica especÃ­fica
run = mlflow.get_run("<RUN_ID>")
accuracy = run.data.metrics["test_accuracy"]
```

---

## ğŸ”„ Flujo de Trabajo Recomendado

### 1. ExperimentaciÃ³n Local

```bash
# Modificar hiperparÃ¡metros en deteccionarritmias.py
# Ejecutar entrenamiento
python deteccionarritmias.py

# Ver resultados
mlflow ui
```

### 2. Comparar y Seleccionar

En MLflow UI:
- Comparar experimentos
- Identificar mejor modelo
- Anotar insights

### 3. Commit y Push

```bash
git add .
git commit -m "Experimento: nuevo focal alpha=0.4"
git push
```

### 4. CI/CD AutomÃ¡tico

GitHub Actions:
- Entrena automÃ¡ticamente
- Valida mÃ©tricas
- Archiva artefactos

### 5. Monitoreo Continuo

Semanalmente:
- Detecta drift
- EvalÃºa rendimiento
- Trigger reentrenamiento si es necesario

---

## ğŸ› Troubleshooting

### No veo mis experimentos en MLflow UI

```powershell
# Verifica que la carpeta mlruns existe
ls mlruns/

# AsegÃºrate de ejecutar mlflow ui en el directorio correcto
cd e:\proyectoML - copia - copia
mlflow ui
```

### Error: "Experiment not found"

```python
# Verificar nombre del experimento
import mlflow
experiments = mlflow.search_experiments()
print([e.name for e in experiments])
```

### GitHub Actions falla en "Verificar datos MIT-BIH"

Los datos MIT-BIH son grandes y no deben estar en Git. Opciones:

1. **Usar DVC** (recomendado):
```bash
dvc init
dvc add mit-bih/
git add mit-bih.dvc .dvc/
```

2. **Descargar en CI** (mÃ¡s lento):
Agregar step de descarga en workflow.

---

## ğŸ“š Recursos Adicionales

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Evidently AI Docs](https://docs.evidentlyai.com/)
- [GitHub Actions](https://docs.github.com/en/actions)
- [Optuna](https://optuna.readthedocs.io/)

---

## ğŸ¯ PrÃ³ximos Pasos

1. **Hyperparameter Tuning con Optuna**
   - OptimizaciÃ³n automÃ¡tica de hiperparÃ¡metros
   - IntegraciÃ³n con MLflow

2. **A/B Testing**
   - Comparar modelos en producciÃ³n
   - Enrutamiento inteligente

3. **Model Serving en Cloud**
   - Despliegue en Azure ML / AWS SageMaker
   - Escalado automÃ¡tico

4. **Dashboards de Monitoreo**
   - Grafana + Prometheus
   - Alertas en tiempo real

---

**Â¿Preguntas?** Consulta el archivo [ARCHITECTURE.md](ARCHITECTURE.md) para mÃ¡s detalles sobre la arquitectura del proyecto.
